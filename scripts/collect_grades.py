#!/usr/bin/env python3
"""
æˆç»©æ”¶é›†å™¨

ä» metadata ä»“åº“ä¸­æ”¶é›†æ‰€æœ‰å­¦ç”Ÿçš„æˆç»©ï¼Œç”Ÿæˆæ±‡æ€» CSV
æ”¯æŒå¤šè¯¾ç¨‹/å¤šä½œä¸šæ¨¡å¼
"""

import os
import sys
from typing import Optional
import argparse
import requests
import csv
import json
import base64
import yaml
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime
from collections import defaultdict
from urllib.parse import urlparse

load_dotenv()


def load_course_config(course_dir):
    config_path = Path(course_dir) / "course_config.yaml"
    if not config_path.exists():
        raise FileNotFoundError(f"Course config not found: {config_path}")
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def detect_host(server_url: str, external_host: Optional[str]) -> str:
    """æ£€æµ‹ Gitea ä¸»æœºåœ°å€"""
    parsed = urlparse(server_url)
    raw_host = parsed.netloc or parsed.path.split("/")[0]
    host = raw_host
    if raw_host.lower().startswith("gitea"):
        host = external_host or "49.234.193.192:3000"
    return host


def list_metadata_files(gitea_url, token, metadata_repo, branch="main", path="records"):
    """
    åˆ—å‡º metadata ä»“åº“ä¸­æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    """
    try:
        owner, repo_name = metadata_repo.split("/", 1)
    except ValueError:
        print(f"Error: Invalid metadata repo format: {metadata_repo}", file=sys.stderr)
        print(f"Expected format: owner/repo", file=sys.stderr)
        return []
    
    # æ£€æµ‹ä¸»æœºåœ°å€
    external_host = os.getenv("EXTERNAL_GITEA_HOST")
    host = detect_host(gitea_url, external_host)
    
    api_url = f"http://{host}/api/v1/repos/{owner}/{repo_name}/contents/{path}"
    
    headers = {
        "Authorization": f"token {token}",
        "Content-Type": "application/json"
    }
    
    params = {
        "ref": branch
    }
    
    all_files = []
    
    def traverse_directory(current_path):
        """é€’å½’éå†ç›®å½•"""
        current_api_url = f"http://{host}/api/v1/repos/{owner}/{repo_name}/contents/{current_path}"
        
        try:
            response = requests.get(current_api_url, headers=headers, params=params, timeout=30)
            response.raise_for_status()
            items = response.json()
            
            # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªæ–‡ä»¶è€Œä¸æ˜¯åˆ—è¡¨
            if isinstance(items, dict):
                items = [items]
            
            for item in items:
                if item.get("type") == "dir":
                    # é€’å½’éå†å­ç›®å½•
                    traverse_directory(item["path"])
                elif item.get("type") == "file" and item["path"].endswith(".json"):
                    # åªæ”¶é›† JSON æ–‡ä»¶
                    all_files.append(item)
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                # ç›®å½•ä¸å­˜åœ¨ï¼Œå¿½ç•¥
                return
            else:
                print(f"Error listing {current_path}: {e}", file=sys.stderr)
        except Exception as e:
            print(f"Error traversing {current_path}: {e}", file=sys.stderr)
    
    traverse_directory(path)
    return all_files


def download_metadata_file(gitea_url, token, metadata_repo, file_path, branch="main"):
    """
    ä¸‹è½½å¹¶è§£æ metadata JSON æ–‡ä»¶
    """
    try:
        owner, repo_name = metadata_repo.split("/", 1)
    except ValueError:
        return None
    
    # æ£€æµ‹ä¸»æœºåœ°å€
    external_host = os.getenv("EXTERNAL_GITEA_HOST")
    host = detect_host(gitea_url, external_host)
    
    api_url = f"http://{host}/api/v1/repos/{owner}/{repo_name}/contents/{file_path}"
    
    headers = {
        "Authorization": f"token {token}",
        "Content-Type": "application/json"
    }
    
    params = {
        "ref": branch
    }
    
    try:
        response = requests.get(api_url, headers=headers, params=params, timeout=30)
        response.raise_for_status()
        file_info = response.json()
        
        # è§£ç  base64 å†…å®¹
        content = file_info.get("content", "")
        # ç§»é™¤å¯èƒ½çš„æ¢è¡Œç¬¦
        content = content.replace("\n", "")
        decoded_content = base64.b64decode(content).decode("utf-8")
        
        # è§£æ JSON
        metadata = json.loads(decoded_content)
        return metadata
    except Exception as e:
        print(f"Error downloading {file_path}: {e}", file=sys.stderr)
        return None


def extract_student_repo_from_path(file_path):
    """
    ä»æ–‡ä»¶è·¯å¾„æå–å­¦ç”Ÿä»“åº“åç§°
    Path format: {assignment_id}/{student_repo}/{filename}
    """
    try:
        # ç§»é™¤ records/ å‰ç¼€ (å…¼å®¹æ—§æ ¼å¼)
        if file_path.startswith("records/"):
            file_path = file_path[8:]
            parts = file_path.split("/")
            if len(parts) >= 2:
                student_safe = parts[0]
                filename = parts[1]
                return student_safe.replace("__", "/"), filename.split("_")[0]
        
        # æ–°æ ¼å¼: hw1/hw1-stu_20250001/grade_...json
        parts = file_path.split("/")
        if len(parts) >= 3:
            # parts[0] is assignment_id (e.g. hw1)
            student_repo = parts[1]  # hw1-stu_20250001
            filename = parts[-1]     # grade_...json
            
            # æå– workflow ç±»å‹ï¼ˆæ–‡ä»¶åç¬¬ä¸€éƒ¨åˆ†ï¼‰
            workflow_type = filename.split("_")[0]
            
            return student_repo, workflow_type
            
        return None, None
    except Exception as e:
        print(f"Error extracting student repo from path {file_path}: {e}", file=sys.stderr)
        return None, None


def merge_components(components_list):
    """
    åˆå¹¶å¤šä¸ª metadata çš„ componentsï¼ŒæŒ‰ type å»é‡ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
    """
    component_dict = {}  # {type: component}
    
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥æŒ‰é¡ºåºåˆå¹¶ï¼Œåé¢çš„ä¼šè¦†ç›–å‰é¢çš„
    for components in components_list:
        for comp in components:
            comp_type = comp.get("type", "unknown")
            # å¯¹äºåŒä¸€ç±»å‹ï¼Œä¿ç•™æœ€æ–°çš„ï¼ˆåé¢è¦†ç›–å‰é¢ï¼‰
            component_dict[comp_type] = comp
    
    return list(component_dict.values())


def main():
    parser = argparse.ArgumentParser(description="Collect grades from metadata repository")
    
    # Required arguments
    parser.add_argument("--course", required=True, help="Path to course directory (e.g., courses/CS101)")
    parser.add_argument("--assignment", required=True, help="Assignment ID (e.g., hw1)")
    
    parser.add_argument("--output", default="grades.csv", help="Output CSV file")
    
    # Optional/Override arguments
    parser.add_argument("--metadata-repo", help="Metadata repository (owner/repo) - auto-inferred if not specified")
    parser.add_argument("--metadata-branch", default=os.getenv("METADATA_BRANCH", "main"),
                       help="Metadata repository branch")
    parser.add_argument("--gitea-url", default=os.getenv("GITEA_URL", "http://localhost:3000"))
    parser.add_argument("--token", default=os.getenv("GITEA_ADMIN_TOKEN", ""))
    parser.add_argument("--prefix", help="Student repository name prefix (for filtering) - auto-inferred if not specified")
    
    args = parser.parse_args()
    
    if not args.token:
        print("Error: GITEA_ADMIN_TOKEN not set", file=sys.stderr)
        print("Hint: Set it via --token or GITEA_ADMIN_TOKEN environment variable", file=sys.stderr)
        sys.exit(1)
    
    print(f"Collecting grades: {args.course} / {args.assignment}")
    course_config = load_course_config(args.course)
    org = course_config.get("organization")
    if not org:
        print("Error: 'organization' not defined in course config", file=sys.stderr)
        sys.exit(1)
        
    # Infer metadata repo and prefix
    # Default to course-metadata, but allow override
    metadata_repo = args.metadata_repo or f"{org}/course-metadata"
    repo_prefix = args.prefix or f"{args.assignment}-stu"

    print(f"ğŸ“¦ Collecting grades from metadata repository: {metadata_repo}")
    print(f"   Branch: {args.metadata_branch}")
    print(f"   Gitea URL: {args.gitea_url}")
    print(f"   Prefix Filter: {repo_prefix}")
    print(f"   Path: {args.assignment}/")
    
    # åˆ—å‡ºæ‰€æœ‰ metadata æ–‡ä»¶
    print("\nğŸ” Scanning metadata files...")
    metadata_files = list_metadata_files(
        args.gitea_url, 
        args.token, 
        metadata_repo,
        args.metadata_branch,
        path=args.assignment
    )
    
    print(f"   Found {len(metadata_files)} metadata files")
    
    if len(metadata_files) == 0:
        print("âš ï¸  No metadata files found", file=sys.stderr)
        print(f"   Hint: Check if metadata repository exists and contains files in 'records/' directory", file=sys.stderr)
        # åˆ›å»ºç©º CSV
        fieldnames = ["student_id", "repo", "status", "score", "max_score", "timestamp", "component_summary", "components"]
        with open(args.output, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
        print(f"\nEmpty CSV created: {args.output}")
        return
    
    # æŒ‰å­¦ç”Ÿåˆ†ç»„æ”¶é›†æˆç»©
    student_grades = defaultdict(lambda: {
        "student_id": None,
        "repo": None,
        "components": [],
        "timestamps": [],
        "status": "no_grade"
    })
    
    print("\nğŸ“¥ Downloading and parsing metadata files...")
    processed = 0
    for file_info in metadata_files:
        file_path = file_info["path"]
        
        # æå–å­¦ç”Ÿä»“åº“ä¿¡æ¯
        student_repo, workflow_type = extract_student_repo_from_path(file_path)
        if not student_repo:
            continue
        
        # è¿‡æ»¤ï¼šåªå¤„ç†åŒ¹é…å‰ç¼€çš„å­¦ç”Ÿä»“åº“
        if repo_prefix and not student_repo.endswith(repo_prefix.split("_")[0] + "_"):
            # æ£€æŸ¥ä»“åº“åæ˜¯å¦åŒ…å«å‰ç¼€
            repo_name = student_repo.split("/")[-1] if "/" in student_repo else student_repo
            if not repo_name.startswith(repo_prefix):
                continue
        
        # ä¸‹è½½å¹¶è§£æ metadata
        metadata = download_metadata_file(
            args.gitea_url,
            args.token,
            metadata_repo,
            file_path,
            args.metadata_branch
        )
        
        if not metadata:
            continue
        
        processed += 1
        
        # æå–å­¦ç”Ÿä¿¡æ¯
        student_id = metadata.get("student_id")
        if not student_id:
            # ä»ä»“åº“åæå–
            repo_name = student_repo.split("/")[-1] if "/" in student_repo else student_repo
            if repo_name.startswith(repo_prefix):
                student_id = repo_name[len(repo_prefix) + 1:]
            else:
                student_id = repo_name
        
        # æ›´æ–°å­¦ç”Ÿæˆç»©ä¿¡æ¯
        if student_grades[student_repo]["student_id"] is None:
            student_grades[student_repo]["student_id"] = student_id
        if student_grades[student_repo]["repo"] is None:
            student_grades[student_repo]["repo"] = student_repo.split("/")[-1] if "/" in student_repo else student_repo
        
        # åˆå¹¶ components
        components = metadata.get("components", [])
        if components:
            student_grades[student_repo]["components"].append(components)
        
        # è®°å½•æ—¶é—´æˆ³
        timestamp = metadata.get("timestamp")
        if timestamp:
            student_grades[student_repo]["timestamps"].append(timestamp)
        
        if processed % 10 == 0:
            print(f"   Processed {processed}/{len(metadata_files)} files...", end="\r")
    
    print(f"\n   âœ… Processed {processed} metadata files")
    
    # ç”Ÿæˆæˆç»©æ±‡æ€»
    print("\nğŸ“Š Generating grade summary...")
    grades = []
    
    for student_repo, grade_info in student_grades.items():
        # åˆå¹¶æ‰€æœ‰ components
        all_components = merge_components(grade_info["components"])
        
        if all_components:
            # è®¡ç®—æ€»åˆ†
            total_score = sum(c.get("score", 0) for c in all_components)
            total_max_score = sum(c.get("max_score", 0) for c in all_components)
            status = "graded"
        else:
            total_score = None
            total_max_score = None
            status = "no_grade"
        
        # è·å–æœ€æ–°æ—¶é—´æˆ³
        timestamps = grade_info["timestamps"]
        latest_timestamp = max(timestamps) if timestamps else None
        
        # ç”Ÿæˆ component æ‘˜è¦
        component_summary = ""
        if all_components:
            component_list = []
            for comp in all_components:
                comp_type = comp.get("type", "unknown")
                comp_score = comp.get("score", 0)
                comp_max = comp.get("max_score", 0)
                component_list.append(f"{comp_type}:{comp_score}/{comp_max}")
            component_summary = " | ".join(component_list)
        
        student_id = grade_info["student_id"] or grade_info["repo"]
        repo_name = grade_info["repo"]
        
        if status == "graded":
            print(f"   âœ… {student_id}: {total_score}/{total_max_score} [{component_summary}]")
        else:
            print(f"   â³ {student_id}: No grade found")
        
        grades.append({
            "student_id": student_id,
            "repo": repo_name,
            "status": status,
            "score": total_score,
            "max_score": total_max_score,
            "timestamp": latest_timestamp,
            "component_summary": component_summary,
            "components": json.dumps(all_components, ensure_ascii=False) if all_components else None
        })
    
    # æŒ‰å­¦å·æ’åº
    grades.sort(key=lambda x: x["student_id"] or "")
    
    # å†™å…¥ CSV
    fieldnames = ["student_id", "repo", "status", "score", "max_score", "timestamp", "component_summary", "components"]
    with open(args.output, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        if grades:
            writer.writerows(grades)
    
    graded_count = sum(1 for g in grades if g["status"] == "graded")
    print(f"\nâœ… Grades saved to {args.output}")
    print(f"   Total students: {len(grades)}")
    print(f"   Graded: {graded_count}")
    print(f"   Not graded: {len(grades) - graded_count}")


if __name__ == "__main__":
    main()
